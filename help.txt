alle Kombinationen ausprobieren:
- Dog-Breed-Classifier-TopModel: https://github.com/KnollFrank/MLND-Dog-Breed-Classifier/blob/master/dog_app.ipynb
- kleines TopModel

- VGG16
- ResNet
- weitere Architekturen aus https://keras.io/applications/

- ImageNet
- COCO (https://github.com/fizyr/keras-retinanet/blob/master/README.md)

mehr Trainingsdaten

versuche folgendes um Ampeln zu erkennen:
- erkenne Ampeln mit Tensorflow Object Detection API (https://github.com/tensorflow/models/tree/master/research/object_detection): :-)
  - erkenne die Ampelfarbe mit Bildverarbeitung oder machine learning.
- 000: Dog-Breed-Classifier-TopModel, VGG16,  ImageNet:
- 001: Dog-Breed-Classifier-TopModel, VGG16,  COCO:
- 010: Dog-Breed-Classifier-TopModel, ResNet, ImageNet:
- 011: Dog-Breed-Classifier-TopModel, ResNet, COCO:
+ 100: kleines TopModel,              VGG16,  ImageNet: :-(
- 101: kleines TopModel,              VGG16,  COCO:
- 110: kleines TopModel,              ResNet, ImageNet:
- 111: kleines TopModel,              ResNet, COCO:

Tensorflow Object Detection API Workflow:
+ alle Ampeln aus den Simulatorbildern mit der Object Detection API extrahieren, labeln und speichern.
- irgendein CNN auf diese extrahierten und gelabelten Bilder anwenden (siehe /home/frankknoll/udacity/SDCND/tmp/transfer_learning_test/transfer_learning.ipynb)

frankknoll@frankknoll-XPS-13-9370:~/udacity/SDCND/CarND-Capstone$ conda env update carnd -f requirements.txt
